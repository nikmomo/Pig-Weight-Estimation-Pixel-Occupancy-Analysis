{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Enviornment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU will be used: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch import nn, optim\n",
    "# import timm \n",
    "\n",
    "# multi-threading\n",
    "import concurrent.futures\n",
    "\n",
    "# Use half of cpu for multi-threading tasks\n",
    "# Consider use gpu if CUDA is available\n",
    "num_workers = os.cpu_count() / 2\n",
    "print(\"Number of CPU will be used:\", num_workers)\n",
    "\n",
    "weight_data = 'Data/final_mapping_original.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Filtering out background\n",
    "\n",
    "Filter out all background and leave a pure pig depth image to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_filter(file_addr):\n",
    "    \n",
    "    # Load image\n",
    "    image = cv2.imread(file_addr)\n",
    "\n",
    "    # Adjust GMM parameters\n",
    "    backSub = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
    "    fgMask = backSub.apply(image)\n",
    "\n",
    "    # Refine the foreground mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    fgMask = cv2.erode(fgMask, kernel, iterations=2)\n",
    "    fgMask = cv2.dilate(fgMask, kernel, iterations=2)\n",
    "\n",
    "    # Convert image to HSV\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define color range for the pig color\n",
    "    lower_color = np.array([110, 255, 254])\n",
    "    upper_color = np.array([255, 255, 255])\n",
    "    color_mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "\n",
    "    # Combine color mask with foreground mask\n",
    "    fgMask = cv2.bitwise_and(fgMask, color_mask)\n",
    "\n",
    "    # Find contours from the mask\n",
    "    contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Assume the largest contour is the pig and create a mask for it\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        refined_mask = np.zeros_like(fgMask)\n",
    "        cv2.fillPoly(refined_mask, [largest_contour], 255)\n",
    "        fgMask = refined_mask\n",
    "\n",
    "    # Extract the foreground using the refined mask\n",
    "    foreground = cv2.bitwise_and(image, image, mask=fgMask)\n",
    "    \n",
    "    return foreground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the filter result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eg_img = 'Data/Week2/20211002/20211002_3342/_Depth_4780.png' # Good example\n",
    "# eg_img = 'Data/Week2/20211002/20211002_3342/_Depth_3223.png' # Good example\n",
    "# eg_img = 'Data/Week2/20211003/20211003_3342a/_Depth_4489.png' # not that bad example\n",
    "eg_img = 'Data/Week1/20210922/20210922_3342/_Depth_5395.png' # Bad example\n",
    "foreground = img_filter(eg_img)\n",
    "\n",
    "# image = cv2.imread(eg_img)\n",
    "# print(\"Total number of pixels after filtering:\", image.shape[0] * image.shape[1])\n",
    "# cv2.imshow('Foreground', foreground)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Count pixels\n",
    "\n",
    "Count the pixels in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_map(img):\n",
    "\n",
    "    # Convert the foreground to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Flatten the image\n",
    "    pixels = img.reshape(-1, img.shape[-1])\n",
    "\n",
    "    # Count unique colors\n",
    "    unique_colors, counts = np.unique(pixels[pixels.sum(axis=1) != 0], axis=0, return_counts=True)\n",
    "\n",
    "    # Create a color map\n",
    "    color_map = {tuple(color): count for color, count in zip(unique_colors, counts)}\n",
    "    \n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test counting pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pixels in map: 51501\n",
      "Color Map: {(0, 0, 255): 841, (0, 1, 255): 671, (0, 2, 254): 285, (0, 2, 255): 629, (0, 3, 255): 786, (0, 4, 255): 828, (0, 5, 254): 333, (0, 5, 255): 700, (0, 6, 255): 630, (0, 7, 255): 1000, (0, 8, 255): 760, (0, 9, 254): 416, (0, 9, 255): 726, (0, 10, 255): 692, (0, 11, 255): 758, (0, 12, 254): 333, (0, 12, 255): 351, (0, 13, 255): 989, (0, 14, 254): 281, (0, 14, 255): 553, (0, 15, 255): 846, (0, 16, 255): 912, (0, 17, 255): 679, (0, 18, 255): 1006, (0, 19, 254): 305, (0, 19, 255): 679, (0, 20, 255): 733, (0, 21, 254): 370, (0, 21, 255): 442, (0, 22, 254): 409, (0, 22, 255): 492, (0, 23, 255): 839, (0, 24, 254): 452, (0, 24, 255): 480, (0, 25, 255): 483, (0, 26, 255): 892, (0, 27, 255): 831, (0, 28, 255): 867, (0, 29, 255): 816, (0, 30, 254): 358, (0, 30, 255): 703, (0, 31, 254): 345, (0, 31, 255): 651, (0, 32, 255): 788, (0, 33, 255): 841, (0, 34, 255): 852, (0, 35, 255): 843, (0, 36, 255): 865, (0, 37, 254): 256, (0, 37, 255): 719, (0, 38, 254): 248, (0, 38, 255): 242, (0, 39, 255): 925, (0, 40, 255): 953, (0, 41, 255): 765, (0, 42, 254): 195, (0, 42, 255): 620, (0, 43, 255): 853, (0, 44, 254): 212, (0, 44, 255): 709, (0, 45, 255): 894, (0, 46, 255): 904, (0, 47, 254): 123, (0, 47, 255): 733, (0, 48, 255): 778, (0, 49, 254): 327, (0, 49, 255): 626, (0, 50, 255): 592, (0, 51, 255): 628, (0, 52, 255): 433, (0, 53, 255): 152, (0, 54, 254): 59, (0, 54, 255): 75, (0, 55, 255): 69, (0, 56, 255): 87, (0, 57, 255): 118, (0, 58, 255): 279, (0, 59, 255): 204, (0, 60, 255): 510, (0, 61, 255): 325, (0, 62, 255): 518, (0, 63, 254): 146, (0, 63, 255): 162, (0, 64, 255): 351, (0, 65, 254): 74, (0, 65, 255): 289, (0, 66, 255): 335, (0, 67, 255): 263, (0, 68, 255): 346, (0, 69, 255): 231, (0, 70, 255): 197, (0, 71, 255): 204, (0, 72, 255): 146, (0, 73, 255): 188, (0, 74, 255): 162, (0, 75, 255): 165, (0, 76, 255): 93, (0, 77, 255): 158, (0, 78, 255): 154, (0, 79, 255): 127, (0, 80, 255): 160, (0, 81, 255): 183, (0, 82, 255): 124, (0, 83, 254): 59, (0, 83, 255): 66, (0, 84, 255): 112, (0, 85, 255): 55, (0, 86, 255): 126, (0, 87, 255): 119, (0, 88, 255): 77, (0, 89, 255): 157}\n"
     ]
    }
   ],
   "source": [
    "foreground = img_filter(eg_img)\n",
    "color_map = get_pixel_map(foreground)\n",
    "print(\"Total number of pixels in map:\", sum(color_map.values()))\n",
    "print(\"Color Map:\", color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Mapping weight w/ pixel map\n",
    "Read weight w/ the pixel map  \n",
    "Use weight, image_path, color_map to access the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_data(row):\n",
    "    image_path = 'Data/' + row[0]\n",
    "    base_name, _ = os.path.splitext(image_path)\n",
    "    image_path = f'{base_name}.png' # Change from jpg to png\n",
    "    # print(image_path)\n",
    "    \n",
    "    # if using whole image files, use this one\n",
    "    if not os.path.exists(image_path): \n",
    "        # print(f\"Image not found: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get the foreground by calling img_filter\n",
    "    foreground = img_filter(image_path)\n",
    "    \n",
    "    # Get the pixel map by calling get_pixel_map\n",
    "    color_map = get_pixel_map(foreground)\n",
    "    \n",
    "    return {\n",
    "                'weight': row[3],\n",
    "                'image_path': image_path,\n",
    "                'color_map': color_map\n",
    "            }\n",
    "            \n",
    "def get_data():\n",
    "    with open(weight_data, mode='r', newline='') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "\n",
    "        # Create a new list to hold the combined data\n",
    "        combined_data = []\n",
    "        headers = next(reader)\n",
    "        \n",
    "        # multi-threading data process\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "            # Start a set of tasks and mark each future with its URL\n",
    "            future_to_task = {executor.submit(img_to_data, arg): arg for arg in reader}\n",
    "            for future in concurrent.futures.as_completed(future_to_task):\n",
    "                arg = future_to_task[future]\n",
    "                try:\n",
    "                    data = future.result()\n",
    "                    combined_data.append(data)\n",
    "                except Exception as exc:\n",
    "                    print(f'{arg} generated an exception: {exc}')\n",
    "                else:\n",
    "                    print(f'{arg} page is {len(data)} bytes')\n",
    "                \n",
    "\n",
    "\n",
    "    # Convert the combined data to a DataFrame\n",
    "    combined_df = pd.DataFrame(combined_data)\n",
    "\n",
    "    # Display the combined DataFrame\n",
    "    # print(combined_df)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test integrated color map and weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/final_mapping_original.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tfgmo\\OneDrive\\Documents\\GitHub\\Pig-Weight-Estimation-Pixel-Occupancy-Analysis\\weight_estimate.ipynb 单元格 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tfgmo/OneDrive/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m get_data()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tfgmo/OneDrive/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(data)\n",
      "\u001b[1;32mc:\\Users\\tfgmo\\OneDrive\\Documents\\GitHub\\Pig-Weight-Estimation-Pixel-Occupancy-Analysis\\weight_estimate.ipynb 单元格 15\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tfgmo/OneDrive/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_data\u001b[39m():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tfgmo/OneDrive/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(weight_data, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m, newline\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m infile:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tfgmo/OneDrive/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         reader \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mreader(infile)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tfgmo/OneDrive/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         \u001b[39m# Create a new list to hold the combined data\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tfgmo\\anaconda3\\envs\\PigPixel\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:308\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    302\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    303\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    305\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m     )\n\u001b[1;32m--> 308\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/final_mapping_original.csv'"
     ]
    }
   ],
   "source": [
    "data = get_data()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
