{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Enviornment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Filtering out background\n",
    "\n",
    "Filter out all background and leave a pure pig depth image to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_filter(file_addr):\n",
    "    \n",
    "    # Load image\n",
    "    image = cv2.imread(file_addr)\n",
    "\n",
    "    # Adjust GMM parameters\n",
    "    backSub = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
    "    fgMask = backSub.apply(image)\n",
    "\n",
    "    # Refine the foreground mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    fgMask = cv2.erode(fgMask, kernel, iterations=2)\n",
    "    fgMask = cv2.dilate(fgMask, kernel, iterations=2)\n",
    "\n",
    "    # Convert image to HSV\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define color range for the pig color\n",
    "    lower_color = np.array([110, 255, 254])\n",
    "    upper_color = np.array([255, 255, 255])\n",
    "    color_mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "\n",
    "    # Combine color mask with foreground mask\n",
    "    fgMask = cv2.bitwise_and(fgMask, color_mask)\n",
    "\n",
    "    # Find contours from the mask\n",
    "    contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Assume the largest contour is the pig and create a mask for it\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        refined_mask = np.zeros_like(fgMask)\n",
    "        cv2.fillPoly(refined_mask, [largest_contour], 255)\n",
    "        fgMask = refined_mask\n",
    "\n",
    "    # Extract the foreground using the refined mask\n",
    "    foreground = cv2.bitwise_and(image, image, mask=fgMask)\n",
    "    \n",
    "    return foreground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the filter result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pixels after filtering: 921600\n"
     ]
    }
   ],
   "source": [
    "# eg_img = 'Data/WEEK1-2/Week1/20210922/20210922_3330_b/_Depth_4618.png' # Good example\n",
    "# eg_img = 'Data/WEEK1-2/Week2/20211003/20211003_3342a/_Depth_4489.png' # Good example\n",
    "eg_img = 'Data/WEEK1-2/Week2/20211003/20211003_3342a/_Depth_6140.png' # Bad example\n",
    "foreground = img_filter(eg_img)\n",
    "\n",
    "# image = cv2.imread(eg_img)\n",
    "# print(\"Total number of pixels after filtering:\", image.shape[0] * image.shape[1])\n",
    "cv2.imshow('Foreground', foreground)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Count pixels\n",
    "\n",
    "Count the pixels in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_map(img):\n",
    "\n",
    "    # Convert the foreground to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Flatten the image\n",
    "    pixels = img.reshape(-1, img.shape[-1])\n",
    "\n",
    "    # Count unique colors\n",
    "    unique_colors, counts = np.unique(pixels[pixels.sum(axis=1) != 0], axis=0, return_counts=True)\n",
    "\n",
    "    # Create a color map\n",
    "    color_map = {tuple(color): count for color, count in zip(unique_colors, counts)}\n",
    "    \n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test counting pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pixels in map: 45570\n",
      "Color Map: {(0, 0, 255): 436, (0, 1, 255): 727, (0, 2, 254): 119, (0, 2, 255): 359, (0, 3, 254): 94, (0, 3, 255): 313, (0, 4, 255): 593, (0, 5, 255): 508, (0, 6, 254): 312, (0, 6, 255): 683, (0, 7, 255): 601, (0, 8, 255): 647, (0, 9, 254): 208, (0, 9, 255): 518, (0, 10, 255): 488, (0, 11, 255): 732, (0, 12, 254): 144, (0, 12, 255): 288, (0, 13, 255): 424, (0, 14, 254): 153, (0, 14, 255): 429, (0, 15, 255): 674, (0, 16, 255): 478, (0, 17, 254): 166, (0, 17, 255): 294, (0, 18, 255): 507, (0, 19, 255): 592, (0, 20, 255): 583, (0, 21, 254): 168, (0, 21, 255): 418, (0, 22, 255): 445, (0, 23, 255): 694, (0, 24, 254): 215, (0, 24, 255): 221, (0, 25, 255): 448, (0, 26, 254): 187, (0, 26, 255): 380, (0, 27, 255): 556, (0, 28, 255): 364, (0, 29, 255): 566, (0, 30, 254): 170, (0, 30, 255): 517, (0, 31, 254): 176, (0, 31, 255): 379, (0, 32, 255): 536, (0, 33, 255): 418, (0, 34, 255): 474, (0, 35, 255): 575, (0, 36, 255): 531, (0, 37, 254): 246, (0, 37, 255): 475, (0, 38, 255): 236, (0, 39, 255): 720, (0, 40, 255): 420, (0, 41, 255): 563, (0, 42, 254): 188, (0, 42, 255): 482, (0, 43, 255): 431, (0, 44, 254): 170, (0, 44, 255): 328, (0, 45, 255): 601, (0, 46, 255): 518, (0, 47, 254): 184, (0, 47, 255): 183, (0, 48, 255): 600, (0, 49, 254): 164, (0, 49, 255): 510, (0, 50, 255): 338, (0, 51, 255): 657, (0, 52, 255): 509, (0, 53, 255): 572, (0, 54, 254): 210, (0, 54, 255): 462, (0, 55, 255): 396, (0, 56, 254): 233, (0, 56, 255): 423, (0, 57, 255): 608, (0, 58, 255): 400, (0, 59, 255): 602, (0, 60, 255): 600, (0, 61, 254): 177, (0, 61, 255): 445, (0, 62, 255): 526, (0, 63, 254): 171, (0, 63, 255): 322, (0, 64, 255): 474, (0, 65, 254): 189, (0, 65, 255): 329, (0, 66, 255): 635, (0, 67, 255): 560, (0, 68, 255): 543, (0, 69, 254): 194, (0, 69, 255): 400, (0, 70, 255): 495, (0, 71, 255): 296, (0, 72, 255): 381, (0, 73, 255): 517, (0, 74, 255): 375, (0, 75, 255): 237, (0, 76, 254): 152, (0, 76, 255): 167, (0, 77, 255): 473, (0, 78, 255): 300, (0, 79, 255): 329, (0, 80, 255): 349, (0, 81, 255): 382, (0, 82, 255): 360, (0, 83, 254): 182, (0, 83, 255): 203, (0, 84, 255): 395, (0, 85, 255): 394, (0, 86, 255): 208, (0, 87, 255): 419, (0, 88, 255): 218, (0, 89, 255): 236}\n"
     ]
    }
   ],
   "source": [
    "foreground = img_filter(eg_img)\n",
    "color_map = get_pixel_map(foreground)\n",
    "print(\"Total number of pixels in map:\", sum(color_map.values()))\n",
    "print(\"Color Map:\", color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
