{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Enviornment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch import nn, optim\n",
    "# import timm \n",
    "\n",
    "weight_data = 'Data/final_mapping_original.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Filtering out background\n",
    "\n",
    "Filter out all background and leave a pure pig depth image to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_filter(file_addr):\n",
    "    \n",
    "    # Load image\n",
    "    image = cv2.imread(file_addr)\n",
    "\n",
    "    # Adjust GMM parameters\n",
    "    backSub = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
    "    fgMask = backSub.apply(image)\n",
    "\n",
    "    # Refine the foreground mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    fgMask = cv2.erode(fgMask, kernel, iterations=2)\n",
    "    fgMask = cv2.dilate(fgMask, kernel, iterations=2)\n",
    "\n",
    "    # Convert image to HSV\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define color range for the pig color\n",
    "    lower_color = np.array([110, 255, 254])\n",
    "    upper_color = np.array([255, 255, 255])\n",
    "    color_mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "\n",
    "    # Combine color mask with foreground mask\n",
    "    fgMask = cv2.bitwise_and(fgMask, color_mask)\n",
    "\n",
    "    # Find contours from the mask\n",
    "    contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Assume the largest contour is the pig and create a mask for it\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        refined_mask = np.zeros_like(fgMask)\n",
    "        cv2.fillPoly(refined_mask, [largest_contour], 255)\n",
    "        fgMask = refined_mask\n",
    "\n",
    "    # Extract the foreground using the refined mask\n",
    "    foreground = cv2.bitwise_and(image, image, mask=fgMask)\n",
    "    \n",
    "    return foreground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the filter result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eg_img = 'Data/Week2/20211002/20211002_3342/_Depth_4780.png' # Good example\n",
    "# eg_img = 'Data/Week2/20211002/20211002_3342/_Depth_3223.png' # Good example\n",
    "# eg_img = 'Data/Week2/20211003/20211003_3342a/_Depth_4489.png' # not that bad example\n",
    "eg_img = 'Data/Week1/20210922/20210922_3342/_Depth_5395.png' # Bad example\n",
    "foreground = img_filter(eg_img)\n",
    "\n",
    "# image = cv2.imread(eg_img)\n",
    "# print(\"Total number of pixels after filtering:\", image.shape[0] * image.shape[1])\n",
    "# cv2.imshow('Foreground', foreground)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Count pixels\n",
    "\n",
    "Count the pixels in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_map(img):\n",
    "\n",
    "    # Convert the foreground to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Flatten the image\n",
    "    pixels = img.reshape(-1, img.shape[-1])\n",
    "\n",
    "    # Count unique colors\n",
    "    unique_colors, counts = np.unique(pixels[pixels.sum(axis=1) != 0], axis=0, return_counts=True)\n",
    "\n",
    "    # Create a color map\n",
    "    color_map = {tuple(color): count for color, count in zip(unique_colors, counts)}\n",
    "    \n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test counting pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pixels in map: 51501\n",
      "Color Map: {(0, 0, 255): 841, (0, 1, 255): 671, (0, 2, 254): 285, (0, 2, 255): 629, (0, 3, 255): 786, (0, 4, 255): 828, (0, 5, 254): 333, (0, 5, 255): 700, (0, 6, 255): 630, (0, 7, 255): 1000, (0, 8, 255): 760, (0, 9, 254): 416, (0, 9, 255): 726, (0, 10, 255): 692, (0, 11, 255): 758, (0, 12, 254): 333, (0, 12, 255): 351, (0, 13, 255): 989, (0, 14, 254): 281, (0, 14, 255): 553, (0, 15, 255): 846, (0, 16, 255): 912, (0, 17, 255): 679, (0, 18, 255): 1006, (0, 19, 254): 305, (0, 19, 255): 679, (0, 20, 255): 733, (0, 21, 254): 370, (0, 21, 255): 442, (0, 22, 254): 409, (0, 22, 255): 492, (0, 23, 255): 839, (0, 24, 254): 452, (0, 24, 255): 480, (0, 25, 255): 483, (0, 26, 255): 892, (0, 27, 255): 831, (0, 28, 255): 867, (0, 29, 255): 816, (0, 30, 254): 358, (0, 30, 255): 703, (0, 31, 254): 345, (0, 31, 255): 651, (0, 32, 255): 788, (0, 33, 255): 841, (0, 34, 255): 852, (0, 35, 255): 843, (0, 36, 255): 865, (0, 37, 254): 256, (0, 37, 255): 719, (0, 38, 254): 248, (0, 38, 255): 242, (0, 39, 255): 925, (0, 40, 255): 953, (0, 41, 255): 765, (0, 42, 254): 195, (0, 42, 255): 620, (0, 43, 255): 853, (0, 44, 254): 212, (0, 44, 255): 709, (0, 45, 255): 894, (0, 46, 255): 904, (0, 47, 254): 123, (0, 47, 255): 733, (0, 48, 255): 778, (0, 49, 254): 327, (0, 49, 255): 626, (0, 50, 255): 592, (0, 51, 255): 628, (0, 52, 255): 433, (0, 53, 255): 152, (0, 54, 254): 59, (0, 54, 255): 75, (0, 55, 255): 69, (0, 56, 255): 87, (0, 57, 255): 118, (0, 58, 255): 279, (0, 59, 255): 204, (0, 60, 255): 510, (0, 61, 255): 325, (0, 62, 255): 518, (0, 63, 254): 146, (0, 63, 255): 162, (0, 64, 255): 351, (0, 65, 254): 74, (0, 65, 255): 289, (0, 66, 255): 335, (0, 67, 255): 263, (0, 68, 255): 346, (0, 69, 255): 231, (0, 70, 255): 197, (0, 71, 255): 204, (0, 72, 255): 146, (0, 73, 255): 188, (0, 74, 255): 162, (0, 75, 255): 165, (0, 76, 255): 93, (0, 77, 255): 158, (0, 78, 255): 154, (0, 79, 255): 127, (0, 80, 255): 160, (0, 81, 255): 183, (0, 82, 255): 124, (0, 83, 254): 59, (0, 83, 255): 66, (0, 84, 255): 112, (0, 85, 255): 55, (0, 86, 255): 126, (0, 87, 255): 119, (0, 88, 255): 77, (0, 89, 255): 157}\n"
     ]
    }
   ],
   "source": [
    "foreground = img_filter(eg_img)\n",
    "color_map = get_pixel_map(foreground)\n",
    "print(\"Total number of pixels in map:\", sum(color_map.values()))\n",
    "print(\"Color Map:\", color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Mapping weight w/ pixel map\n",
    "Read weight w/ the pixel map  \n",
    "Use weight, image_path, color_map to access the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    with open(weight_data, mode='r', newline='') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "\n",
    "        # Create a new list to hold the combined data\n",
    "        combined_data = []\n",
    "        headers = next(reader)\n",
    "\n",
    "        # Loop through each row in the DataFrame\n",
    "        for row in reader:\n",
    "            # print(row)\n",
    "            # Read the image using the image path\n",
    "            image_path = 'Data/' + row[0]\n",
    "            base_name, _ = os.path.splitext(image_path)\n",
    "            image_path = f'{base_name}.png' # Change from jpg to png\n",
    "            # print(image_path)\n",
    "            \n",
    "            # if using whole image files, use this one\n",
    "            if not os.path.exists(image_path): \n",
    "                # print(f\"Image not found: {image_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Check if the image file exists\n",
    "            # if not os.path.exists(image_path) or \\\n",
    "            #     not ('Week1/20210922/20210922_3330_b' in image_path): # or 'Week2' in image_path):\n",
    "            #     print(f\"Image not found: {image_path}\")\n",
    "            #     continue\n",
    "            \n",
    "            # Get the foreground by calling img_filter\n",
    "            foreground = img_filter(image_path)\n",
    "            \n",
    "            # Get the pixel map by calling get_pixel_map\n",
    "            color_map = get_pixel_map(foreground)\n",
    "            \n",
    "            # Append the weight, image path, and color map to the combined_data list\n",
    "            combined_data.append({\n",
    "                'weight': row[3],\n",
    "                'image_path': image_path,\n",
    "                'color_map': color_map\n",
    "            })\n",
    "\n",
    "    # Convert the combined data to a DataFrame\n",
    "    combined_df = pd.DataFrame(combined_data)\n",
    "\n",
    "    # Display the combined DataFrame\n",
    "    # print(combined_df)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test integrated color map and weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Niko\\Documents\\GitHub\\Pig-Weight-Estimation-Pixel-Occupancy-Analysis\\weight_estimate.ipynb 单元格 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m get_data()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(data)\n",
      "\u001b[1;32mc:\\Users\\Niko\\Documents\\GitHub\\Pig-Weight-Estimation-Pixel-Occupancy-Analysis\\weight_estimate.ipynb 单元格 15\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X22sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X22sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Check if the image file exists\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X22sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# if not os.path.exists(image_path) or \\\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X22sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m#     not ('Week1/20210922/20210922_3330_b' in image_path): # or 'Week2' in image_path):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X22sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X22sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Get the foreground by calling img_filter\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X22sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m foreground \u001b[39m=\u001b[39m img_filter(image_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X22sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Get the pixel map by calling get_pixel_map\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X22sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m color_map \u001b[39m=\u001b[39m get_pixel_map(foreground)\n",
      "\u001b[1;32mc:\\Users\\Niko\\Documents\\GitHub\\Pig-Weight-Estimation-Pixel-Occupancy-Analysis\\weight_estimate.ipynb 单元格 15\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimg_filter\u001b[39m(file_addr):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# Load image\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(file_addr)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# Adjust GMM parameters\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     backSub \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcreateBackgroundSubtractorMOG2(history\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, varThreshold\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, detectShadows\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = get_data()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
