{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Enviornment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU will be used: 8.0\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch import nn, optim\n",
    "# import timm \n",
    "\n",
    "# multi-threading\n",
    "import concurrent.futures\n",
    "\n",
    "# Use half of cpu for multi-threading tasks\n",
    "# Consider use gpu if CUDA is available\n",
    "num_workers = os.cpu_count() / 2\n",
    "print(\"Number of CPU will be used:\", num_workers)\n",
    "\n",
    "weight_data = 'Data/final_mapping_original.csv'\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA available:\", cuda_available)\n",
    "if cuda_available:\n",
    "    print(\"CUDA version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Filtering out background\n",
    "\n",
    "Filter out all background and leave a pure pig depth image to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_filter(file_addr):\n",
    "    \n",
    "    # Load image\n",
    "    image = cv2.imread(file_addr)\n",
    "\n",
    "    # Adjust GMM parameters\n",
    "    backSub = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
    "    fgMask = backSub.apply(image)\n",
    "\n",
    "    # Refine the foreground mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    fgMask = cv2.erode(fgMask, kernel, iterations=2)\n",
    "    fgMask = cv2.dilate(fgMask, kernel, iterations=2)\n",
    "\n",
    "    # Convert image to HSV\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define color range for the pig color\n",
    "    lower_color = np.array([110, 255, 254])\n",
    "    upper_color = np.array([255, 255, 255])\n",
    "    color_mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "\n",
    "    # Combine color mask with foreground mask\n",
    "    fgMask = cv2.bitwise_and(fgMask, color_mask)\n",
    "\n",
    "    # Find contours from the mask\n",
    "    contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Assume the largest contour is the pig and create a mask for it\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        refined_mask = np.zeros_like(fgMask)\n",
    "        cv2.fillPoly(refined_mask, [largest_contour], 255)\n",
    "        fgMask = refined_mask\n",
    "\n",
    "    # Extract the foreground using the refined mask\n",
    "    foreground = cv2.bitwise_and(image, image, mask=fgMask)\n",
    "    \n",
    "    return foreground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the filter result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eg_img = 'Data/Week2/20211002/20211002_3342/_Depth_4780.png' # Good example\n",
    "# eg_img = 'Data/Week2/20211002/20211002_3342/_Depth_3223.png' # Good example\n",
    "# eg_img = 'Data/Week2/20211003/20211003_3342a/_Depth_4489.png' # not that bad example\n",
    "eg_img = 'Data/Week1/20210922/20210922_3342/_Depth_5395.png' # Bad example\n",
    "foreground = img_filter(eg_img)\n",
    "\n",
    "# image = cv2.imread(eg_img)\n",
    "# print(\"Total number of pixels after filtering:\", image.shape[0] * image.shape[1])\n",
    "# cv2.imshow('Foreground', foreground)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Count pixels\n",
    "\n",
    "Count the pixels in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_map(img):\n",
    "\n",
    "    # Convert the foreground to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Flatten the image\n",
    "    pixels = img.reshape(-1, img.shape[-1])\n",
    "\n",
    "    # Count unique colors\n",
    "    unique_colors, counts = np.unique(pixels[pixels.sum(axis=1) != 0], axis=0, return_counts=True)\n",
    "\n",
    "    # Create a color map\n",
    "    color_map = {tuple(color): count for color, count in zip(unique_colors, counts)}\n",
    "    \n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test counting pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pixels in map: 51501\n",
      "Color Map: {(0, 0, 255): 841, (0, 1, 255): 671, (0, 2, 254): 285, (0, 2, 255): 629, (0, 3, 255): 786, (0, 4, 255): 828, (0, 5, 254): 333, (0, 5, 255): 700, (0, 6, 255): 630, (0, 7, 255): 1000, (0, 8, 255): 760, (0, 9, 254): 416, (0, 9, 255): 726, (0, 10, 255): 692, (0, 11, 255): 758, (0, 12, 254): 333, (0, 12, 255): 351, (0, 13, 255): 989, (0, 14, 254): 281, (0, 14, 255): 553, (0, 15, 255): 846, (0, 16, 255): 912, (0, 17, 255): 679, (0, 18, 255): 1006, (0, 19, 254): 305, (0, 19, 255): 679, (0, 20, 255): 733, (0, 21, 254): 370, (0, 21, 255): 442, (0, 22, 254): 409, (0, 22, 255): 492, (0, 23, 255): 839, (0, 24, 254): 452, (0, 24, 255): 480, (0, 25, 255): 483, (0, 26, 255): 892, (0, 27, 255): 831, (0, 28, 255): 867, (0, 29, 255): 816, (0, 30, 254): 358, (0, 30, 255): 703, (0, 31, 254): 345, (0, 31, 255): 651, (0, 32, 255): 788, (0, 33, 255): 841, (0, 34, 255): 852, (0, 35, 255): 843, (0, 36, 255): 865, (0, 37, 254): 256, (0, 37, 255): 719, (0, 38, 254): 248, (0, 38, 255): 242, (0, 39, 255): 925, (0, 40, 255): 953, (0, 41, 255): 765, (0, 42, 254): 195, (0, 42, 255): 620, (0, 43, 255): 853, (0, 44, 254): 212, (0, 44, 255): 709, (0, 45, 255): 894, (0, 46, 255): 904, (0, 47, 254): 123, (0, 47, 255): 733, (0, 48, 255): 778, (0, 49, 254): 327, (0, 49, 255): 626, (0, 50, 255): 592, (0, 51, 255): 628, (0, 52, 255): 433, (0, 53, 255): 152, (0, 54, 254): 59, (0, 54, 255): 75, (0, 55, 255): 69, (0, 56, 255): 87, (0, 57, 255): 118, (0, 58, 255): 279, (0, 59, 255): 204, (0, 60, 255): 510, (0, 61, 255): 325, (0, 62, 255): 518, (0, 63, 254): 146, (0, 63, 255): 162, (0, 64, 255): 351, (0, 65, 254): 74, (0, 65, 255): 289, (0, 66, 255): 335, (0, 67, 255): 263, (0, 68, 255): 346, (0, 69, 255): 231, (0, 70, 255): 197, (0, 71, 255): 204, (0, 72, 255): 146, (0, 73, 255): 188, (0, 74, 255): 162, (0, 75, 255): 165, (0, 76, 255): 93, (0, 77, 255): 158, (0, 78, 255): 154, (0, 79, 255): 127, (0, 80, 255): 160, (0, 81, 255): 183, (0, 82, 255): 124, (0, 83, 254): 59, (0, 83, 255): 66, (0, 84, 255): 112, (0, 85, 255): 55, (0, 86, 255): 126, (0, 87, 255): 119, (0, 88, 255): 77, (0, 89, 255): 157}\n"
     ]
    }
   ],
   "source": [
    "foreground = img_filter(eg_img)\n",
    "color_map = get_pixel_map(foreground)\n",
    "print(\"Total number of pixels in map:\", sum(color_map.values()))\n",
    "print(\"Color Map:\", color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Mapping weight w/ pixel map\n",
    "Read weight w/ the pixel map  \n",
    "Use weight, image_path, color_map to access the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_data(row):\n",
    "    image_path = 'Data/' + row[0]\n",
    "    base_name, _ = os.path.splitext(image_path)\n",
    "    image_path = f'{base_name}.png' # Change from jpg to png\n",
    "    # print(image_path)\n",
    "    \n",
    "    # if using whole image files, use this one\n",
    "    if not os.path.exists(image_path): \n",
    "        # print(f\"Image not found: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get the foreground by calling img_filter\n",
    "    foreground = img_filter(image_path)\n",
    "    \n",
    "    # Get the pixel map by calling get_pixel_map\n",
    "    color_map = get_pixel_map(foreground)\n",
    "    \n",
    "    return {\n",
    "                'weight': row[3],\n",
    "                'image_path': image_path,\n",
    "                'color_map': color_map\n",
    "            }\n",
    "            \n",
    "def get_data():\n",
    "    with open(weight_data, mode='r', newline='') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "\n",
    "        # Create a new list to hold the combined data\n",
    "        combined_data = []\n",
    "        headers = next(reader)\n",
    "        \n",
    "        # multi-threading data process\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "            # Start a set of tasks and mark each future with its URL\n",
    "            future_to_task = {executor.submit(img_to_data, arg): arg for arg in reader}\n",
    "            for future in concurrent.futures.as_completed(future_to_task):\n",
    "                arg = future_to_task[future]\n",
    "                try:\n",
    "                    data = future.result()\n",
    "                    combined_data.append(data)\n",
    "                except Exception as exc:\n",
    "                    print(f'{arg} generated an exception: {exc}')\n",
    "                # else:\n",
    "                #     print(f'{arg} page is {len(data)} bytes')\n",
    "                \n",
    "    # filter out nonetypes\n",
    "    combined_data = [item for item in combined_data if item is not None and isinstance(item, dict)]\n",
    "    \n",
    "    # Convert the combined data to a DataFrame\n",
    "    combined_df = pd.DataFrame(combined_data)\n",
    "\n",
    "    # Display the combined DataFrame\n",
    "    # print(combined_df)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Gather all data and export the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Niko\\Documents\\GitHub\\Pig-Weight-Estimation-Pixel-Occupancy-Analysis\\weight_estimate.ipynb 单元格 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m get_data()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m csv_file_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mData/data.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m data\u001b[39m.\u001b[39mto_csv(csv_file_path, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\Niko\\Documents\\GitHub\\Pig-Weight-Estimation-Pixel-Occupancy-Analysis\\weight_estimate.ipynb 单元格 15\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m                 \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00marg\u001b[39m}\u001b[39;00m\u001b[39m generated an exception: \u001b[39m\u001b[39m{\u001b[39;00mexc\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m             \u001b[39m# else:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m             \u001b[39m#     print(f'{arg} page is {len(data)} bytes')\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m             \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# Convert the combined data to a DataFrame\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m combined_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(combined_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# Display the combined DataFrame\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# print(combined_df)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Pig-Weight-Estimation-Pixel-Occupancy-Analysis/weight_estimate.ipynb#X20sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mreturn\u001b[39;00m combined_df\n",
      "File \u001b[1;32mc:\\Users\\Niko\\anaconda3\\envs\\PigPixel\\Lib\\site-packages\\pandas\\core\\frame.py:806\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    804\u001b[0m     \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    805\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 806\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    807\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    808\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    809\u001b[0m         data,\n\u001b[0;32m    810\u001b[0m         columns,\n\u001b[0;32m    811\u001b[0m         index,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    812\u001b[0m         dtype,\n\u001b[0;32m    813\u001b[0m     )\n\u001b[0;32m    814\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    815\u001b[0m         arrays,\n\u001b[0;32m    816\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    819\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    820\u001b[0m     )\n\u001b[0;32m    821\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Niko\\anaconda3\\envs\\PigPixel\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[39mif\u001b[39;00m is_named_tuple(data[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    518\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_fields)\n\u001b[1;32m--> 520\u001b[0m arrays, columns \u001b[39m=\u001b[39m to_arrays(data, columns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    521\u001b[0m columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    523\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Niko\\anaconda3\\envs\\PigPixel\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:837\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    835\u001b[0m     arr \u001b[39m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m    836\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data[\u001b[39m0\u001b[39m], abc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m--> 837\u001b[0m     arr, columns \u001b[39m=\u001b[39m _list_of_dict_to_arrays(data, columns)\n\u001b[0;32m    838\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m    839\u001b[0m     arr, columns \u001b[39m=\u001b[39m _list_of_series_to_arrays(data, columns)\n",
      "File \u001b[1;32mc:\\Users\\Niko\\anaconda3\\envs\\PigPixel\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:917\u001b[0m, in \u001b[0;36m_list_of_dict_to_arrays\u001b[1;34m(data, columns)\u001b[0m\n\u001b[0;32m    915\u001b[0m     gen \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m(x\u001b[39m.\u001b[39mkeys()) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data)\n\u001b[0;32m    916\u001b[0m     sort \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(d, \u001b[39mdict\u001b[39m) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data)\n\u001b[1;32m--> 917\u001b[0m     pre_cols \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mfast_unique_multiple_list_gen(gen, sort\u001b[39m=\u001b[39;49msort)\n\u001b[0;32m    918\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(pre_cols)\n\u001b[0;32m    920\u001b[0m \u001b[39m# assure that they are of the base dict class and not of derived\u001b[39;00m\n\u001b[0;32m    921\u001b[0m \u001b[39m# classes\u001b[39;00m\n",
      "File \u001b[1;32mlib.pyx:393\u001b[0m, in \u001b[0;36mpandas._libs.lib.fast_unique_multiple_list_gen\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Niko\\anaconda3\\envs\\PigPixel\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:915\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    895\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    896\u001b[0m \u001b[39mConvert list of dicts to numpy arrays\u001b[39;00m\n\u001b[0;32m    897\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[39mcolumns : Index\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m     gen \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m(x\u001b[39m.\u001b[39;49mkeys()) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data)\n\u001b[0;32m    916\u001b[0m     sort \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(d, \u001b[39mdict\u001b[39m) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data)\n\u001b[0;32m    917\u001b[0m     pre_cols \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mfast_unique_multiple_list_gen(gen, sort\u001b[39m=\u001b[39msort)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "data = get_data()\n",
    "\n",
    "csv_file_path = 'Data/data.csv'\n",
    "data.to_csv(csv_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
